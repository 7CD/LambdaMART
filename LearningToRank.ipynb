{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningToRank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ_EeuNENCJX"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ9u3oJQNEkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc893084-7ab0-4a24-bb80-5bcc60868a7c"
      },
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1UazU8Dd1ZahFPKQL4bqgapfkqiZax6SO'\n",
        "output = './l2r.tar.gz'\n",
        "\n",
        "if not os.path.exists(output):\n",
        "    gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UazU8Dd1ZahFPKQL4bqgapfkqiZax6SO\n",
            "To: /content/l2r.tar.gz\n",
            "516MB [00:08, 60.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZfjbZY0IAyd"
      },
      "source": [
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(output, \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSSjViTITp6X"
      },
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "train_csr, train_y, train_qid = load_svmlight_file(\"l2r/train.txt.gz\", query_id=True)\n",
        "\n",
        "test_csr, test_y, test_qid = load_svmlight_file(\"l2r/test.txt.gz\", query_id=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGpUtIVTpmY-"
      },
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lszYb9FhppnK",
        "outputId": "cdda78cd-98e2-498d-8e41-96ac34804f8d"
      },
      "source": [
        "train_csr[:2]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2x699 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 373 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSDqoaXDp_I3",
        "outputId": "710f0bbe-7532-48be-ff4a-ce38c1a9d0a4"
      },
      "source": [
        "train_y[15:25]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1., 1., 2., 0., 1., 4., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUQJgPORb8DJ",
        "outputId": "8506f511-4806-45df-c99e-73b63392b4d9"
      },
      "source": [
        "train_qid[15:25]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, 4, 4, 4, 5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKfuWCfvrBk0"
      },
      "source": [
        "# There are some invalid samples\n",
        "import pandas as pd\n",
        "\n",
        "docs_by_query = pd.DataFrame({'doc_index' : np.arange(len(train_y)), 'labels' : train_y, 'query' : train_qid}, index=train_qid)\n",
        "\n",
        "good_indexes = []\n",
        "\n",
        "for query in set(train_qid):\n",
        "  try:\n",
        "    if len(set(docs_by_query.loc[query].values[:, 1])) > 1:\n",
        "      good_indexes.extend(docs_by_query.loc[query, 'doc_index'].values)\n",
        "  except:\n",
        "    continue\n",
        "  \n",
        "train_csr = train_csr[good_indexes]\n",
        "train_qid = train_qid[good_indexes]\n",
        "train_y = train_y[good_indexes]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRbODe6YqRxS"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhyrnEDRDAC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def max_dcg_score(doc_labels):\n",
        "  t = np.sort(doc_labels)[::-1]\n",
        "  return np.sum((np.power(2, t) - 1) / np.log2(np.arange(2, len(t) + 2)))\n",
        "\n",
        "\n",
        "def dcg_score(scores, labels):\n",
        "  documents = np.arange(len(labels))\n",
        "  documents_order_according_to_scores = documents[(-scores).argsort()]\n",
        "  return np.sum((np.power(2, labels[documents_order_according_to_scores]) - 1) / np.log2(documents + 2))\n",
        "\n",
        "\n",
        "def group_by_ids(a, group_ids):\n",
        "  a, ids = np.array(a), np.array(group_ids)\n",
        "  id_bounds_idxs = [0]\n",
        "  id_bounds_idxs.extend((ids[1:] != ids[:-1]).nonzero()[0] + 1)\n",
        "  id_bounds_idxs.append(len(ids))\n",
        "  a_layed_out = []\n",
        "  for i in range(len(id_bounds_idxs)-1):\n",
        "    a_layed_out.append(a[id_bounds_idxs[i] : id_bounds_idxs[i + 1]])\n",
        "  return a_layed_out"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMpygH1OqnOJ"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class LambdaMART:\n",
        "  def __init__(self, n_trees=5, max_depth=8, learning_rate=0.5, dcg_k=-1):\n",
        "    self.n_trees = n_trees\n",
        "    self.max_depth = max_depth\n",
        "    self.learning_rate = learning_rate\n",
        "    self.trees = []\n",
        "    # self.k = dcg_k\n",
        " \n",
        "  def fit(self, X, y, query_ids):\n",
        "    assert X.shape[0] == len(y)\n",
        "    n_samples = X.shape[0]\n",
        "\n",
        "    y_by_query = group_by_ids(y, query_ids)\n",
        "    model_scores_by_query = [np.zeros(len(scores)) for scores in y_by_query]\n",
        "    max_dcg_by_query = [max_dcg_score(scores) for scores in y_by_query]\n",
        "    # max_dcg_at_k(scores, self.dcg_k)\n",
        "    \n",
        "    for k in tqdm(range(self.n_trees)):\n",
        "      lambdas, w = np.zeros(n_samples), np.zeros(n_samples)\n",
        "      doc_idx = 0\n",
        "      \n",
        "      for y, model_scores, max_DCG in zip(y_by_query, model_scores_by_query, max_dcg_by_query):\n",
        "        n_docs = len(y)\n",
        "        doc_ranks_predicted = np.zeros(n_docs, dtype=np.int64) \n",
        "        doc_ranks_predicted[(-model_scores).argsort()] = np.arange(n_docs)\n",
        "\n",
        "        for y_i, s_i, rank_i in zip(y, model_scores, doc_ranks_predicted):\n",
        "          indices_j = (y != y_i)\n",
        "          y_j, s_j, rank_j = y[indices_j], model_scores[indices_j], doc_ranks_predicted[indices_j]\n",
        "\n",
        "          delta_DCG = np.abs(\n",
        "              (np.power(2, y_i) - np.power(2, y_j)) * \n",
        "              (1. / np.log2(rank_i + 2.) - 1. / np.log2(rank_j + 2.))\n",
        "          )\n",
        "          rho_i_j = 1. / (1. + np.exp(np.abs(s_i - s_j)))\n",
        "          lambda_i_j = -rho_i_j * delta_DCG\n",
        "\n",
        "          lambda_i = (np.sign(y_i - y_j) * lambda_i_j).sum() / max_DCG\n",
        "          w_i = (rho_i_j * (1 - rho_i_j) * delta_DCG).sum() / max_DCG\n",
        "\n",
        "          lambdas[doc_idx], w[doc_idx] = lambda_i, w_i\n",
        "          doc_idx += 1\n",
        "      \n",
        "      tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=10)\n",
        "      tree.fit(X, lambdas)\n",
        " \n",
        "      model_scores = np.concatenate(model_scores_by_query)\n",
        "      leaf_by_doc_index = tree.apply(X)\n",
        "\n",
        "      for leaf in set(leaf_by_doc_index):\n",
        "        one_leaf_docs_indices = np.where(leaf_by_doc_index == leaf)[0]\n",
        "        gamma_l_k = lambdas[one_leaf_docs_indices].sum() / w[one_leaf_docs_indices].sum()\n",
        "        tree.tree_.value[leaf] = -gamma_l_k * self.learning_rate\n",
        "        model_scores[one_leaf_docs_indices] -= gamma_l_k * self.learning_rate\n",
        "      \n",
        "      model_scores_by_query = group_by_ids(model_scores, query_ids)\n",
        "      \n",
        "      self.trees.append(tree)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    model_scores = np.zeros(X.shape[0])\n",
        "    for tree in self.trees:\n",
        "      model_scores += tree.predict(X)\n",
        "    return model_scores"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zvo5P6zqvXc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yp_2kLNr5M7"
      },
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "train_idx, val_idx = next(gss.split(train_csr, train_y, train_qid))\n",
        "\n",
        "X_train, y_train, qid_train = train_csr[train_idx], train_y[train_idx], train_qid[train_idx]\n",
        "\n",
        "X_val, y_val, qid_val = train_csr[val_idx], train_y[val_idx], train_qid[val_idx]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_E8YH7sqrTu",
        "outputId": "334e464c-18a4-478e-a861-80d3ba05cf1c"
      },
      "source": [
        "model = LambdaMART(5, 3, 0.2)\n",
        "model.fit(X_train, y_train, qid_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [03:20<00:00, 40.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTy6qNRNuTZG"
      },
      "source": [
        "def get_ndcg_score(scores, labels, query_ids):\n",
        "  scores_grouped = group_by_ids(scores, query_ids)\n",
        "  labels_grouped = group_by_ids(labels, query_ids)\n",
        "\n",
        "  dcg = np.array([dcg_score(scores, labels) for scores, labels in zip(scores_grouped, labels_grouped)])\n",
        "  max_dcg = np.array([max_dcg_score(labels) for labels in labels_grouped])\n",
        "\n",
        "  ndcg = val_dcg / val_max_dcg\n",
        "\n",
        "  return np.mean(ndcg)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRbBywwBvAGo"
      },
      "source": [
        "pred = model.predict(X_val)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wspBWjMjvPoh",
        "outputId": "0cb3bf11-ff84-49a1-a7de-2ea51c2f1552"
      },
      "source": [
        "get_ndcg_score(pred, y_val, qid_val)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8039031198639267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzxyy3Lku0YR"
      },
      "source": [
        "# Submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cqrGGI_u1xL"
      },
      "source": [
        "def order_docs(doc_scores, qids):\n",
        "    assert len(doc_scores) == len(qids)\n",
        "    doc_ids = np.arange(1, len(doc_scores) + 1)\n",
        "    ordered_docs = np.zeros(len(doc_scores), dtype=np.int32)\n",
        "    \n",
        "    qid_prev = qids[0]\n",
        "    i_prev = 0\n",
        "\n",
        "    for i, qid_i in enumerate(qids):\n",
        "        if qid_i != qid_prev:\n",
        "            ordered_docs[i_prev:i] = doc_ids[np.argsort(-doc_scores[i_prev:i]) + i_prev]\n",
        "            i_prev = i\n",
        "            qid_prev = qid_i\n",
        "    ordered_docs[i_prev:] = doc_ids[np.argsort(-doc_scores[i_prev:]) + i_prev]\n",
        "    \n",
        "    return ordered_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DklLhqU86Lk"
      },
      "source": [
        "!mkdir -p /root/.kaggle\n",
        "!cp kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9wgRtZ98Wro",
        "outputId": "cd054efb-6d1c-49c4-8e7d-92bae4cf6b9c"
      },
      "source": [
        "import kaggle\n",
        "\n",
        "pred = model.predict(test_csr)\n",
        "\n",
        "sample = pd.read_csv('l2r/sample.made.fall.2019')\n",
        "docs = order_docs(pred, sample['QueryId'].values)\n",
        "sample['DocumentId'] = docs\n",
        "sample.to_csv('submission.txt', index=False)\n",
        "\n",
        "kaggle.api.competition_submit('submission.txt', '', 'learning-to-rank-made-fall-2019')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.83M/2.83M [00:10<00:00, 291kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Successfully submitted to Learning to rank MADE Fall 2019"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5c1bzoC8WvB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}